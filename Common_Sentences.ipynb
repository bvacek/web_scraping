{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Common Sentences in <i> The X-Files</i>.\n",
    "\n",
    "Wikipedia has an article for every episode of the television show ['The X-Files'](https://en.wikipedia.org/wiki/The_X-Files). These articles contain lots of copy/pasted information.\n",
    "\n",
    "I wanted to see what sentences were the most common in the articles and what percentage of the articles contain each sentence.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "import cufflinks as cf\n",
    "cf.set_config_file(offline=False, world_readable=True, theme='ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = get_soup('https://en.wikipedia.org/wiki/List_of_The_X-Files_episodes')\n",
    "tables = soup.find_all('table', {'class':'wikitable plainrowheaders wikiepisodetable'})\n",
    "links = []\n",
    "for table in tables:\n",
    "    rows = table.find_all('td', {'class':'summary'})\n",
    "    for i in rows:\n",
    "        links.append('https://en.wikipedia.org' + i.find('a')['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining and Cleaning the data\n",
    "\n",
    "I used requests and beautiful soup to get a list of links from the wiki page containing [every X Files episode.](https://en.wikipedia.org/wiki/List_of_The_X-Files_episodes)\n",
    "\n",
    "I then downloaded every page linked (219 articles) and used a simple cleaning method to isolate the body of the article and remove unwanted formatting characters such as newlines and \"\\\"s and also removed any period that didn't mark the end of a sentence (for instance \"Washington D.C.\" became \"Washington DC\"). This makes it easier to break the article into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paragraphs(soup):    \n",
    "    paragraphs = []\n",
    "    for i in soup.find_all('p'):\n",
    "        #identifies all p elements that contain alphanumeric characters\n",
    "        if re.search('[a-zA-Z]',i.text):\n",
    "            #removes all instances of \"\\\" and newline\n",
    "            text = re.sub('[\\\\\\n]','',i.text)\n",
    "            #searches for periods that are preceded by a single uppercase character and removes them.\n",
    "            text = re.sub(r'(?<!\\w)([A-Z])\\.', r'', text)\n",
    "            paragraphs.append(text)\n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219\n"
     ]
    }
   ],
   "source": [
    "paras = []\n",
    "for count,i in enumerate(links):\n",
    "    paras.append(get_paragraphs(get_soup(i)))\n",
    "    print(int(count/len(links)*100),end = '\\r')\n",
    "print(len(paras))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Since the only periods remaining were sentence enders, and Wikipedia doesn't end sentences with \"!\" or \"?\", I could split the articles into sentences by finding the periods. \n",
    "\n",
    "The only problem was my regex function missed the abbreviation \"Dr.\" because the period is preceded by a lowercase character. Since there were only 10 instances of the word, I decided the best solution was to just remove it entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for i in paras:\n",
    "    for j in i:\n",
    "        for k in j.split('. '):\n",
    "            if k != '':\n",
    "                sentences.append(k.lower())\n",
    "\n",
    "series = pd.Series(sentences)\n",
    "series = series[series != 'dr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis and Visualization\n",
    "\n",
    "I used Pandas and Plotly for this portion.\n",
    "\n",
    "The table shows the top 10 sentences, how many articles each appeared in, and what percentage of all 219 articles they appeared in. The graph shows the same 10 sentences with their absolute frequencies on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~benvacek/56.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Sentence' : series.value_counts().keys(),\n",
    "                   'Count': series.value_counts().values\n",
    "                  })\n",
    "df['Percentage'] = df['Count'].apply(lambda x: round(x/len(paras)*100,2), 1)\n",
    "trace0 = go.Table(\n",
    "    columnorder = [1,2,3,4],\n",
    "    columnwidth = [40,80,80,400],\n",
    "    header = dict(values = ['','Count', 'Percentage','Sentence'], align = ['center','center','center','center'],\n",
    "                  font = dict(color = 'white', size = 14),\n",
    "                  fill = dict(color = ['#f2f2f2','#ec8879']),\n",
    "                  height = 30),\n",
    "    cells = dict(values = [[1,2,3,4,5,6,7,8,9,10],df['Count'].head(10),df['Percentage'].head(10),df['Sentence'].head(10)], \n",
    "                 align = ['center','center','center', 'left'],\n",
    "                 fill = dict(color = ['#f2f2f2','white','#f2f2f2','white']),\n",
    "                 height = 50)\n",
    ")\n",
    "\n",
    "py.iplot([trace0], filename='common_sentences_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~benvacek/58.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.value_counts().head(10).iplot(kind='bar', title = 'Most Common Sentences', filename='most_common_sentences_chart')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Findings\n",
    "\n",
    "Many of the articles show signs of copy/pasting:\n",
    "\n",
    "* <b>61.64%</b> of the articles contained the sentence <i>\"The show centers on FBI Special Agents Fox Mulder (David Duchovny) and Dana Scully (Gillian Anderson) who work on cases linked to the paranormal, called X-Files\"</i>. Two of the other most common sentences mirror this one closely but add in the characters <i>\"John Doggett (Robert Patrick)\"</i> and <i>\"Monica Reyes (Annabeth Gish)\"</i>, who were both late additions to the show.\n",
    "\n",
    "\n",
    "* Another <b>30.59%</b> contained <i>\"Mulder is a believer in the paranormal, while the skeptical Scully has been assigned to debunk his work.\"</i>\n",
    "\n",
    "\n",
    "* and <b>over a quarter</b> contained <i>\"The episode is a \"Monster-of-the-Week\" story unconnected to the series' wider mythology\".</i> Close variations of this sentence also occur quite frequently and make up 3 of the top 10 spots. Combining their frequencies, sentences mentioning the term <i>\"Monster-of-the-Week\"</i> occur in <b>35%</b> of the 219 articles."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
